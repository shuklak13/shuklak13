<html>
<title>Responsible AI</title>

<h1>Responsible AI</h1>

<h2>Mission</h2>

<p>I am working to make <b>transparency</b>, <b>interpretability</b>, and <b>controllability</b> a core part of the AI software user experience.</p>

<h2>What does this mean?</h2>

<p>Users should have insight into the AI systems powering the products they use every day. They should understand (1) how their interactions shape a product's behavior, (2) how recommendations are generated from data, and (3) how we as developers have worked to ensure that these products are safe and effective for a wide range of users. Furthermore, users should be empowered to influence the product in a way that best fits their own needs.</p>

<h2>Why is this important?</h2>

<p>Modern software products handle massive amounts of user data and have a massive impact on society. This scale and impact can raise real concerns about how these systems operate.</p>

<p>It's our responsibility to address the concerns of our users. When we provide information and control to users, we earn their trust, and can provide an experience that better serves our users and society.</p>

<h2>How can we do it?</h2>

<p>We need to build more new software infrastructure to make critical ML information and artifacts available and accessible.</p>

<p>Once we have built these tools, we can provide solutions to product developers for better user experience and better governance.</p>

<h2>Contact me</h2>

<p>If you're interested in collaborating on this mission, please get in touch! My email is <a href = "mailto:me@karanshukla.com">me@karanshukla.com</a>.</p>

<h2>Learn More</h2>

<ul>
<li> <a href = "https://ai.google/responsibilities/responsible-ai-practices/">Google's Responsible AI Practices</a></li>
<li> <a href = "https://ec.europa.eu/info/sites/default/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf">On Artificial Intelligence - A European approach to excellence and trust</a></li>
</ul>

</html>